# Chatbot Service Infrastructure (`infra/chatbot`)

This directory contains Terraform configuration (.tf files) responsible for provisioning and managing the AWS infrastructure required for the Real Madrid AI project's **Chatbot** service.

## Architecture Overview

This Terraform setup deploys the following AWS resources:

1. **AWS Lambda Function (`chatbot-microservice`):**
    * Runs the core chatbot logic.
    * Deployed using a Docker image specified by `var.ecr_image_uri`.
    * Uses ARM64 architecture for potential cost/performance benefits.
    * Configured with a 15-second timeout and 512MB memory.
    * Requires a `GEMINI_API_KEY` environment variable.
    * Has AWS X-Ray tracing enabled (`Active`).
2. **Amazon API Gateway V2 (HTTP API) (`chatbot-api`):**
    * Provides a public HTTP endpoint to invoke the Lambda function.
    * Configured with routes:
        * `POST /chat`: Primary route for chat interactions.
        * `GET /`: Root route (likely for health checks or basic info).
    * Uses `AWS_PROXY` integration with the Lambda function.
    * Includes a `$default` stage with auto-deployment enabled.
3. **AWS ECR Repository (`chatbot-lambda-repo`):**
    * A private container registry to store the Docker image for the Lambda function.
    * Set to `force_delete = true`, meaning the repository can be deleted even if it contains images (use with caution).
4. **IAM Role (`chatbot-lambda-exec-role`):**
    * Execution role assumed by the Lambda function.
    * Grants permissions for:
        * Basic Lambda execution (via managed policy `AWSLambdaBasicExecutionRole`).
        * Writing logs to CloudWatch (via custom policy `lambda-logging-policy`).
        * Sending trace data to AWS X-Ray (via managed policy `AWSXRayDaemonWriteAccess`).
5. **CloudWatch Resources:**
    * **Log Group (`/aws/lambda/chatbot-microservice`):** Stores logs generated by the Lambda function, with a 7-day retention period.
    * **Dashboard (`chatbot-service-dashboard`):** Provides basic monitoring for Lambda Invocations, Errors, and P90 Duration. *(Note: Dashboard name based on default variable value in `monitoring.tf`)*.
    * **Alarms:**
        * `chatbot-service-HighErrors`: Triggers if any errors occur within a 1-minute period.
        * `chatbot-service-HighLatency`: Triggers if the P90 duration exceeds 1000ms (1 second) within a 1-minute period.

## Prerequisites

* **Terraform CLI:** Ensure Terraform is installed (check with `terraform version`).
* **AWS Account & Credentials:** You need an AWS account and your credentials must be configured correctly for Terraform to use (e.g., via environment variables, AWS credentials file, or IAM role).
* **Docker Image:** A Docker image containing the chatbot service code must be built and pushed to the specified ECR repository URI (`var.ecr_image_uri`) **before** applying this Terraform configuration. The `source_code_hash` in `main.tf` implies changes to the referenced Dockerfile will trigger Lambda updates.

## Configuration

The following input variables are defined in `variables.tf` and need values:

* `ecr_image_uri`: (Required) The full URI (including the tag, e.g., `:latest`) of the pre-built Docker image in your AWS ECR repository.
* `gemini_api_key`: (Required) The API key needed by the chatbot Lambda function to interact with the Gemini service.

Values for these variables are typically provided in the `terraform.tfvars` file.

**Security Note:** The `terraform.tfvars` file included stores the `gemini_api_key` directly. For production or shared environments, it is strongly recommended **not** to commit secrets directly into version control. Consider using more secure methods like:

* Setting the variable via environment variables (`export TF_VAR_gemini_api_key="..."`).
* Using AWS Secrets Manager or Systems Manager Parameter Store and referencing the secrets within Terraform.
* Using `.tfvars` files that are *not* committed to Git (and listed in `.gitignore`).

## Outputs

After a successful `apply`, Terraform will output the following:

* `api_gateway_invoke_url`: The base URL for invoking your deployed API Gateway. The specific chatbot endpoint will be `{api_gateway_invoke_url}/chat`.

## Monitoring

* Basic Lambda performance can be viewed on the CloudWatch Dashboard named `chatbot-service-dashboard`.
* Alarms are configured to trigger on errors or high P90 latency. Configure notifications for these alarms (e.g., via SNS) as needed.
* Detailed logs are available in the `/aws/lambda/chatbot-microservice` CloudWatch Log Group.
* AWS X-Ray tracing can be used for more in-depth request analysis.
